{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMg3HeAxxgay1aJ8cnk2jJm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/psse-cpu/ml-workshop/blob/main/notebooks/playground/mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "F-n_lUVb-n7Z",
        "outputId": "a834f59b-00b5-4d6c-8e44-ba8d8d20ede4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.set_printoptions(precision=3, suppress=True, linewidth=320)\n",
        "\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "id": "T9CDr_5Q_A_p"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_images.shape, training_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3btOjwzm_Vn6",
        "outputId": "51219ea6-af60-42af-c61d-137079ad53c1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images.shape, test_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qhk02NA0_aB8",
        "outputId": "816d3302-5c7e-4680-d4fa-6c0c14dbb712"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 28, 28), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_images_norm = training_images / 255.0\n",
        "test_images_norm = test_images / 255.0"
      ],
      "metadata": {
        "id": "15P80pBs_gVl"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_images_norm[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq46TCHp_vAG",
        "outputId": "9bb85e08-9d2d-4880-fece-4e268d3435c1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.004, 0.   , 0.   , 0.051, 0.286, 0.   , 0.   , 0.004, 0.016, 0.   , 0.   , 0.   , 0.   , 0.004, 0.004, 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.012, 0.   , 0.141, 0.533, 0.498, 0.243, 0.212, 0.   , 0.   , 0.   , 0.004, 0.012, 0.016, 0.   , 0.   , 0.012],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.024, 0.   , 0.4  , 0.8  , 0.69 , 0.525, 0.565, 0.482, 0.09 , 0.   , 0.   , 0.   , 0.   , 0.047, 0.039, 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.608, 0.925, 0.812, 0.698, 0.42 , 0.612, 0.631, 0.427, 0.251, 0.09 , 0.302, 0.51 , 0.282, 0.059],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.004, 0.   , 0.271, 0.812, 0.875, 0.855, 0.847, 0.847, 0.639, 0.498, 0.475, 0.478, 0.573, 0.553, 0.345, 0.675, 0.259],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.004, 0.004, 0.004, 0.   , 0.784, 0.91 , 0.91 , 0.914, 0.898, 0.875, 0.875, 0.843, 0.835, 0.643, 0.498, 0.482, 0.769, 0.898, 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.718, 0.882, 0.847, 0.875, 0.894, 0.922, 0.89 , 0.878, 0.871, 0.878, 0.867, 0.875, 0.961, 0.678, 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.757, 0.894, 0.855, 0.835, 0.776, 0.706, 0.831, 0.824, 0.827, 0.835, 0.875, 0.863, 0.953, 0.792, 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.004, 0.012, 0.   , 0.047, 0.859, 0.863, 0.831, 0.855, 0.753, 0.663, 0.89 , 0.816, 0.855, 0.878, 0.831, 0.886, 0.773, 0.82 , 0.204],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.024, 0.   , 0.388, 0.957, 0.871, 0.863, 0.855, 0.796, 0.776, 0.867, 0.843, 0.835, 0.871, 0.863, 0.961, 0.467, 0.655, 0.22 ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.016, 0.   , 0.   , 0.216, 0.925, 0.894, 0.902, 0.894, 0.941, 0.91 , 0.835, 0.855, 0.875, 0.918, 0.851, 0.851, 0.82 , 0.361, 0.   ],\n",
              "       [0.   , 0.   , 0.004, 0.016, 0.024, 0.027, 0.008, 0.   , 0.   , 0.   , 0.   , 0.   , 0.929, 0.886, 0.851, 0.875, 0.871, 0.859, 0.871, 0.867, 0.847, 0.875, 0.898, 0.843, 0.855, 1.   , 0.302, 0.   ],\n",
              "       [0.   , 0.012, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.243, 0.569, 0.8  , 0.894, 0.812, 0.835, 0.867, 0.855, 0.816, 0.827, 0.855, 0.878, 0.875, 0.859, 0.843, 0.878, 0.957, 0.624, 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.071, 0.173, 0.322, 0.42 , 0.741, 0.894, 0.863, 0.871, 0.851, 0.886, 0.784, 0.804, 0.827, 0.902, 0.878, 0.918, 0.69 , 0.737, 0.98 , 0.973, 0.914, 0.933, 0.843, 0.   ],\n",
              "       [0.   , 0.224, 0.733, 0.816, 0.878, 0.867, 0.878, 0.816, 0.8  , 0.839, 0.816, 0.82 , 0.784, 0.624, 0.961, 0.757, 0.808, 0.875, 1.   , 1.   , 0.867, 0.918, 0.867, 0.827, 0.863, 0.91 , 0.965, 0.   ],\n",
              "       [0.012, 0.792, 0.894, 0.878, 0.867, 0.827, 0.827, 0.839, 0.804, 0.804, 0.804, 0.863, 0.941, 0.314, 0.588, 1.   , 0.898, 0.867, 0.737, 0.604, 0.749, 0.824, 0.8  , 0.82 , 0.871, 0.894, 0.882, 0.   ],\n",
              "       [0.384, 0.914, 0.776, 0.824, 0.871, 0.898, 0.898, 0.918, 0.976, 0.863, 0.761, 0.843, 0.851, 0.945, 0.255, 0.286, 0.416, 0.459, 0.659, 0.859, 0.867, 0.843, 0.851, 0.875, 0.875, 0.878, 0.898, 0.114],\n",
              "       [0.294, 0.8  , 0.831, 0.8  , 0.757, 0.804, 0.827, 0.882, 0.847, 0.725, 0.773, 0.808, 0.776, 0.835, 0.941, 0.765, 0.89 , 0.961, 0.937, 0.875, 0.855, 0.831, 0.82 , 0.871, 0.863, 0.867, 0.902, 0.263],\n",
              "       [0.188, 0.796, 0.718, 0.761, 0.835, 0.773, 0.725, 0.745, 0.761, 0.753, 0.792, 0.839, 0.859, 0.867, 0.863, 0.925, 0.882, 0.847, 0.78 , 0.808, 0.729, 0.71 , 0.694, 0.675, 0.71 , 0.804, 0.808, 0.451],\n",
              "       [0.   , 0.478, 0.859, 0.757, 0.702, 0.671, 0.718, 0.769, 0.8  , 0.824, 0.835, 0.812, 0.827, 0.824, 0.784, 0.769, 0.761, 0.749, 0.765, 0.749, 0.776, 0.753, 0.69 , 0.612, 0.655, 0.694, 0.824, 0.361],\n",
              "       [0.   , 0.   , 0.29 , 0.741, 0.831, 0.749, 0.686, 0.675, 0.686, 0.71 , 0.725, 0.737, 0.741, 0.737, 0.757, 0.776, 0.8  , 0.82 , 0.824, 0.824, 0.827, 0.737, 0.737, 0.761, 0.753, 0.847, 0.667, 0.   ],\n",
              "       [0.008, 0.   , 0.   , 0.   , 0.259, 0.784, 0.871, 0.929, 0.937, 0.949, 0.965, 0.953, 0.957, 0.867, 0.863, 0.757, 0.749, 0.702, 0.714, 0.714, 0.71 , 0.69 , 0.651, 0.659, 0.388, 0.227, 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.157, 0.239, 0.173, 0.282, 0.161, 0.137, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images_norm[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDl55ytjACOT",
        "outputId": "d448fd05-b363-4982-c40e-da05cf3381c0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.012, 0.004, 0.   , 0.   , 0.027, 0.   , 0.145, 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.004, 0.008, 0.   , 0.106, 0.329, 0.043, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.467, 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.004, 0.   , 0.   , 0.345, 0.561, 0.431, 0.   , 0.   , 0.   , 0.   , 0.086, 0.365, 0.416, 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.016, 0.   , 0.208, 0.506, 0.471, 0.576, 0.686, 0.616, 0.651, 0.529, 0.604, 0.659, 0.549, 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.008, 0.   , 0.043, 0.537, 0.51 , 0.502, 0.627, 0.69 , 0.624, 0.655, 0.698, 0.584, 0.592, 0.565, 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.004, 0.   , 0.008, 0.004, 0.   , 0.012, 0.   , 0.   , 0.451, 0.447, 0.416, 0.537, 0.659, 0.6  , 0.612, 0.647, 0.655, 0.561, 0.616, 0.62 , 0.043, 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.004, 0.   , 0.   , 0.   , 0.   , 0.   , 0.012, 0.   , 0.   , 0.349, 0.545, 0.353, 0.369, 0.6  , 0.584, 0.514, 0.592, 0.663, 0.675, 0.561, 0.624, 0.663, 0.188, 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.008, 0.016, 0.004, 0.   , 0.   , 0.   , 0.384, 0.533, 0.431, 0.427, 0.431, 0.635, 0.529, 0.565, 0.584, 0.624, 0.655, 0.565, 0.62 , 0.663, 0.467, 0.   ],\n",
              "       [0.   , 0.   , 0.008, 0.008, 0.004, 0.008, 0.   , 0.   , 0.   , 0.   , 0.102, 0.424, 0.459, 0.388, 0.435, 0.459, 0.533, 0.612, 0.525, 0.604, 0.604, 0.612, 0.627, 0.553, 0.576, 0.612, 0.698, 0.   ],\n",
              "       [0.012, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.082, 0.208, 0.361, 0.459, 0.435, 0.404, 0.451, 0.506, 0.525, 0.561, 0.604, 0.647, 0.667, 0.604, 0.592, 0.604, 0.561, 0.541, 0.588, 0.647, 0.169],\n",
              "       [0.   , 0.   , 0.09 , 0.212, 0.255, 0.298, 0.333, 0.463, 0.502, 0.482, 0.435, 0.443, 0.463, 0.498, 0.49 , 0.545, 0.522, 0.533, 0.627, 0.549, 0.608, 0.631, 0.565, 0.608, 0.675, 0.631, 0.741, 0.243],\n",
              "       [0.   , 0.267, 0.369, 0.353, 0.435, 0.447, 0.435, 0.447, 0.451, 0.498, 0.529, 0.533, 0.561, 0.494, 0.498, 0.592, 0.604, 0.561, 0.58 , 0.49 , 0.635, 0.635, 0.565, 0.541, 0.6  , 0.635, 0.769, 0.227],\n",
              "       [0.275, 0.663, 0.506, 0.408, 0.384, 0.392, 0.369, 0.38 , 0.384, 0.4  , 0.424, 0.416, 0.467, 0.471, 0.506, 0.584, 0.612, 0.655, 0.745, 0.745, 0.769, 0.776, 0.776, 0.733, 0.773, 0.741, 0.722, 0.141],\n",
              "       [0.063, 0.494, 0.671, 0.737, 0.737, 0.722, 0.671, 0.6  , 0.529, 0.471, 0.494, 0.498, 0.573, 0.725, 0.765, 0.82 , 0.816, 1.   , 0.82 , 0.694, 0.961, 0.988, 0.984, 0.984, 0.969, 0.863, 0.808, 0.192],\n",
              "       [0.   , 0.   , 0.   , 0.047, 0.263, 0.416, 0.643, 0.725, 0.78 , 0.824, 0.827, 0.824, 0.816, 0.745, 0.588, 0.322, 0.031, 0.   , 0.   , 0.   , 0.698, 0.816, 0.737, 0.686, 0.635, 0.62 , 0.592, 0.043],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_info(model):\n",
        "    model.summary()\n",
        "\n",
        "    for layer in model.layers:\n",
        "        if (isinstance(layer, keras.layers.Dense)):\n",
        "            print(f'Layer name: {layer.name};\\tActivation: {layer.activation.__name__}')\n",
        "        else:\n",
        "            print(f'Layer name: {layer.name}')\n",
        "\n",
        "    print(f'Optimizer: {model.optimizer}')\n",
        "\n",
        "def train(**kwargs):\n",
        "    # default activation for hidden layers is sigmoid\n",
        "    hidden_layers_activation = kwargs.get('hidden_layers_activation', 'sigmoid')\n",
        "    optimizer = kwargs.get('optimizer', keras.optimizers.SGD())\n",
        "    normalize = kwargs.get('normalize', True)\n",
        "    epochs = kwargs.get('epochs', 5)\n",
        "\n",
        "    # default to one hidden layer with 128 neurons\n",
        "    hidden_layers_units = kwargs.get('hidden_layers_units', [128])\n",
        "    hidden_layers = [\n",
        "        keras.layers.Dense(units, hidden_layers_activation) \n",
        "        for units in hidden_layers_units\n",
        "    ]\n",
        "\n",
        "    X_train = training_images_norm if normalize else training_images\n",
        "    X_test = test_images_norm if normalize else test_images\n",
        "\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(),\n",
        "        *hidden_layers, \n",
        "        keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer, loss=keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
        "    model.fit(X_train, training_labels, epochs=epochs)\n",
        "    show_info(model)\n",
        "\n",
        "    model.evaluate(X_test, test_labels)"
      ],
      "metadata": {
        "id": "cDV2CoyXACks"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train(hidden_layers_units=[128])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNCeJbyaA36W",
        "outputId": "df1169b6-e16c-4f04-acc1-67559d06033c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.2652 - accuracy: 0.6677\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.7650 - accuracy: 0.7524\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.6586 - accuracy: 0.7749\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.6033 - accuracy: 0.7918\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.5665 - accuracy: 0.8044\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_17 (Flatten)        (32, 784)                 0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (32, 128)                 100480    \n",
            "                                                                 \n",
            " dense_38 (Dense)            (32, 10)                  1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Layer name: flatten_17\n",
            "Layer name: dense_37;\tActivation: sigmoid\n",
            "Layer name: dense_38;\tActivation: softmax\n",
            "Optimizer: <keras.optimizer_v2.gradient_descent.SGD object at 0x7f2db9817f10>\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.5713 - accuracy: 0.7994\n",
            "CPU times: user 26.7 s, sys: 3.36 s, total: 30 s\n",
            "Wall time: 25.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "train(hidden_layers_activation='relu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUYcM1D6HhiI",
        "outputId": "2771f715-1aec-4772-f8f1-f720bfc69095"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.7407 - accuracy: 0.7636\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.5101 - accuracy: 0.8260\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4655 - accuracy: 0.8409\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4416 - accuracy: 0.8474\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4242 - accuracy: 0.8534\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_18 (Flatten)        (32, 784)                 0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (32, 128)                 100480    \n",
            "                                                                 \n",
            " dense_40 (Dense)            (32, 10)                  1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Layer name: flatten_18\n",
            "Layer name: dense_39;\tActivation: relu\n",
            "Layer name: dense_40;\tActivation: softmax\n",
            "Optimizer: <keras.optimizer_v2.gradient_descent.SGD object at 0x7f2db9838610>\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4622 - accuracy: 0.8366\n",
            "CPU times: user 26.4 s, sys: 3.35 s, total: 29.8 s\n",
            "Wall time: 25.1 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "train(optimizer=keras.optimizers.Adam())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsqvgVJMIIdd",
        "outputId": "9f03ce17-7532-4a55-b20d-a8399598b8df"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5451 - accuracy: 0.8134\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3922 - accuracy: 0.8582\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3554 - accuracy: 0.8720\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3300 - accuracy: 0.8799\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3100 - accuracy: 0.8876\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_19 (Flatten)        (32, 784)                 0         \n",
            "                                                                 \n",
            " dense_41 (Dense)            (32, 128)                 100480    \n",
            "                                                                 \n",
            " dense_42 (Dense)            (32, 10)                  1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Layer name: flatten_19\n",
            "Layer name: dense_41;\tActivation: sigmoid\n",
            "Layer name: dense_42;\tActivation: softmax\n",
            "Optimizer: <keras.optimizer_v2.adam.Adam object at 0x7f2db973bc10>\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3591 - accuracy: 0.8703\n",
            "CPU times: user 28.1 s, sys: 3.19 s, total: 31.3 s\n",
            "Wall time: 43.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "train(hidden_layers_activation='relu', optimizer=keras.optimizers.Adam())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e05TW6hJIT63",
        "outputId": "654abe21-616f-4d00-a677-e3c61081cc1f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5015 - accuracy: 0.8242\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3776 - accuracy: 0.8648\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3390 - accuracy: 0.8774\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3140 - accuracy: 0.8857\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2973 - accuracy: 0.8907\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_20 (Flatten)        (32, 784)                 0         \n",
            "                                                                 \n",
            " dense_43 (Dense)            (32, 128)                 100480    \n",
            "                                                                 \n",
            " dense_44 (Dense)            (32, 10)                  1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Layer name: flatten_20\n",
            "Layer name: dense_43;\tActivation: relu\n",
            "Layer name: dense_44;\tActivation: softmax\n",
            "Optimizer: <keras.optimizer_v2.adam.Adam object at 0x7f2dbf527710>\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3533 - accuracy: 0.8763\n",
            "CPU times: user 27.6 s, sys: 3.21 s, total: 30.9 s\n",
            "Wall time: 43 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "train(\n",
        "    hidden_layers_activation='relu', \n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    hidden_layers_units=[512]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRmtiGHUJ95k",
        "outputId": "3ca65ecd-a68e-41ad-da4b-ef771095422d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4753 - accuracy: 0.8303\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3542 - accuracy: 0.8699\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3212 - accuracy: 0.8812\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2963 - accuracy: 0.8893\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2786 - accuracy: 0.8965\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_21 (Flatten)        (32, 784)                 0         \n",
            "                                                                 \n",
            " dense_45 (Dense)            (32, 512)                 401920    \n",
            "                                                                 \n",
            " dense_46 (Dense)            (32, 10)                  5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Layer name: flatten_21\n",
            "Layer name: dense_45;\tActivation: relu\n",
            "Layer name: dense_46;\tActivation: softmax\n",
            "Optimizer: <keras.optimizer_v2.adam.Adam object at 0x7f2dc00a7350>\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3412 - accuracy: 0.8807\n",
            "CPU times: user 30.4 s, sys: 3.12 s, total: 33.5 s\n",
            "Wall time: 28.7 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "train(\n",
        "    hidden_layers_activation='relu', \n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    hidden_layers_units=[1024]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sFegYvBKjpS",
        "outputId": "a81a9ec4-44da-41e0-e6e8-c34fb9122e36"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4720 - accuracy: 0.8308\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3596 - accuracy: 0.8685\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3194 - accuracy: 0.8820\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2970 - accuracy: 0.8882\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2791 - accuracy: 0.8951\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_22 (Flatten)        (32, 784)                 0         \n",
            "                                                                 \n",
            " dense_47 (Dense)            (32, 1024)                803840    \n",
            "                                                                 \n",
            " dense_48 (Dense)            (32, 10)                  10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 814,090\n",
            "Trainable params: 814,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Layer name: flatten_22\n",
            "Layer name: dense_47;\tActivation: relu\n",
            "Layer name: dense_48;\tActivation: softmax\n",
            "Optimizer: <keras.optimizer_v2.adam.Adam object at 0x7f2e303b0350>\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3305 - accuracy: 0.8811\n",
            "CPU times: user 33.9 s, sys: 3.45 s, total: 37.4 s\n",
            "Wall time: 32.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "train(\n",
        "    hidden_layers_activation='relu', \n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    hidden_layers_units=[128],\n",
        "    epochs=15\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uweh_tzDLKui",
        "outputId": "e86e4fbb-668e-48b5-e873-3a07577da2ba"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4977 - accuracy: 0.8253\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3767 - accuracy: 0.8642\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3392 - accuracy: 0.8762\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3172 - accuracy: 0.8844\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2981 - accuracy: 0.8894\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2813 - accuracy: 0.8964\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2711 - accuracy: 0.8996\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2573 - accuracy: 0.9036\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2505 - accuracy: 0.9067\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2395 - accuracy: 0.9114\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2316 - accuracy: 0.9139\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2254 - accuracy: 0.9153\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2169 - accuracy: 0.9186\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2098 - accuracy: 0.9215\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2052 - accuracy: 0.9230\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_23 (Flatten)        (32, 784)                 0         \n",
            "                                                                 \n",
            " dense_49 (Dense)            (32, 128)                 100480    \n",
            "                                                                 \n",
            " dense_50 (Dense)            (32, 10)                  1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Layer name: flatten_23\n",
            "Layer name: dense_49;\tActivation: relu\n",
            "Layer name: dense_50;\tActivation: softmax\n",
            "Optimizer: <keras.optimizer_v2.adam.Adam object at 0x7f2e30089c10>\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3762 - accuracy: 0.8743\n",
            "CPU times: user 1min 22s, sys: 9.05 s, total: 1min 31s\n",
            "Wall time: 1min 23s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "train(\n",
        "    hidden_layers_activation='relu', \n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    hidden_layers_units=[128, 128],\n",
        "    epochs=30\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_6cNlQpNj2O",
        "outputId": "403c70a7-dab9-4c78-8e70-4fb209ef8c81"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4876 - accuracy: 0.8247\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3626 - accuracy: 0.8674\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3271 - accuracy: 0.8780\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3058 - accuracy: 0.8869\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2873 - accuracy: 0.8927\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2715 - accuracy: 0.8974\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2632 - accuracy: 0.9014\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2494 - accuracy: 0.9051\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2425 - accuracy: 0.9085\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2329 - accuracy: 0.9104\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2234 - accuracy: 0.9148\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2158 - accuracy: 0.9179\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2071 - accuracy: 0.9212\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2009 - accuracy: 0.9234\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1938 - accuracy: 0.9258\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1881 - accuracy: 0.9283\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1855 - accuracy: 0.9285\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1788 - accuracy: 0.9312\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1728 - accuracy: 0.9334\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1688 - accuracy: 0.9346\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1613 - accuracy: 0.9376\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1612 - accuracy: 0.9386\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1539 - accuracy: 0.9400\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1505 - accuracy: 0.9426\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1468 - accuracy: 0.9435\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1457 - accuracy: 0.9442\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1410 - accuracy: 0.9458\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1354 - accuracy: 0.9473\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1355 - accuracy: 0.9482\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1301 - accuracy: 0.9499\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_16 (Flatten)        (32, 784)                 0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (32, 128)                 100480    \n",
            "                                                                 \n",
            " dense_35 (Dense)            (32, 128)                 16512     \n",
            "                                                                 \n",
            " dense_36 (Dense)            (32, 10)                  1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Layer name: flatten_16\n",
            "Layer name: dense_34;\tActivation: relu\n",
            "Layer name: dense_35;\tActivation: relu\n",
            "Layer name: dense_36;\tActivation: softmax\n",
            "Optimizer: <keras.optimizer_v2.adam.Adam object at 0x7f2dbf466f50>\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4378 - accuracy: 0.8913\n",
            "CPU times: user 2min 46s, sys: 18.3 s, total: 3min 5s\n",
            "Wall time: 3min 24s\n"
          ]
        }
      ]
    }
  ]
}