{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/psse-cpu/ml-workshop/blob/main/notebooks/workshop-templates/multivariate.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workshop, you'll predict the salary of an applicant, given the data of other\n",
    "applicants and the salary they're offered.\n",
    "\n",
    "- `column 1:` [Microsoft Python Certification Exam][1] score\n",
    "  * passing score is 28, so the range here is 28 to 40\n",
    "- `column 2:` years experience\n",
    "  * so far, we have applicants from 1 year to 12  years experience\n",
    "- `column 3:` monthly salary offered, $x100,000$ pesos\n",
    "\n",
    "> 👀 large values like the salary need to be scaled down, otherwise your MSE will be very very high.\n",
    "> Remember that before getting the average, we get the SUM first\n",
    "> and sum of squared errors of LARGE numbers like 150k salary can go towards $\\infty$\n",
    "\n",
    "[1]: https://www.udemy.com/course/microsoft-python-certification-exam-98-381-practice-tests/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from random import randrange\n",
    "\n",
    "# 3 decimal places, suppress scientific notation\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, data like these are loaded from CSV files, or databases, but that would require the participants\n",
    "to learn another library, with its own set of [invented syntax](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf) that heavily uses\n",
    "[operator overloading](https://datapythonista.me/blog/python-operators-and-how-they-affect-pandas.html).  \n",
    "\n",
    "Ain't got no time for that in our 3 hour workshop.  So let's just use a hardcoded Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([\n",
    "    [28.   ,  1.   ,  0.801],\n",
    "    [28.   ,  2.   ,  0.758],\n",
    "    [28.   ,  3.   ,  0.785],\n",
    "    [28.   ,  4.   ,  0.862],\n",
    "    [28.   ,  5.   ,  0.799],\n",
    "    [28.   ,  6.   ,  0.836],\n",
    "    [28.   ,  7.   ,  0.783],\n",
    "    [28.   ,  8.   ,  0.8  ],\n",
    "    [28.   ,  9.   ,  0.887],\n",
    "    [28.   , 10.   ,  0.904],\n",
    "    [28.   , 11.   ,  0.831],\n",
    "    [28.   , 12.   ,  0.848],\n",
    "    [29.   ,  1.   ,  0.839],\n",
    "    [29.   ,  2.   ,  0.836],\n",
    "    [29.   ,  3.   ,  0.803],\n",
    "    [29.   ,  4.   ,  0.83 ],\n",
    "    [29.   ,  5.   ,  0.877],\n",
    "    [29.   ,  6.   ,  0.884],\n",
    "    [29.   ,  7.   ,  0.871],\n",
    "    [29.   ,  8.   ,  0.888],\n",
    "    [29.   ,  9.   ,  0.915],\n",
    "    [29.   , 10.   ,  0.912],\n",
    "    [29.   , 11.   ,  0.859],\n",
    "    [29.   , 12.   ,  0.876],\n",
    "    [30.   ,  1.   ,  0.857],\n",
    "    [30.   ,  2.   ,  0.854],\n",
    "    [30.   ,  3.   ,  0.841],\n",
    "    [30.   ,  4.   ,  0.818],\n",
    "    [30.   ,  5.   ,  0.825],\n",
    "    [30.   ,  6.   ,  0.852],\n",
    "    [30.   ,  7.   ,  0.849],\n",
    "    [30.   ,  8.   ,  0.876],\n",
    "    [30.   ,  9.   ,  0.873],\n",
    "    [30.   , 10.   ,  0.88 ],\n",
    "    [30.   , 11.   ,  0.947],\n",
    "    [30.   , 12.   ,  0.964],\n",
    "    [31.   ,  1.   ,  0.825],\n",
    "    [31.   ,  2.   ,  0.912],\n",
    "    [31.   ,  3.   ,  0.909],\n",
    "    [31.   ,  4.   ,  0.856],\n",
    "    [31.   ,  5.   ,  0.893],\n",
    "    [31.   ,  6.   ,  0.91 ],\n",
    "    [31.   ,  7.   ,  0.867],\n",
    "    [31.   ,  8.   ,  0.974],\n",
    "    [31.   ,  9.   ,  0.921],\n",
    "    [31.   , 10.   ,  0.888],\n",
    "    [31.   , 11.   ,  0.905],\n",
    "    [31.   , 12.   ,  0.952],\n",
    "    [32.   ,  1.   ,  0.943],\n",
    "    [32.   ,  2.   ,  0.88 ],\n",
    "    [32.   ,  3.   ,  0.877],\n",
    "    [32.   ,  4.   ,  0.904],\n",
    "    [32.   ,  5.   ,  0.891],\n",
    "    [32.   ,  6.   ,  0.898],\n",
    "    [32.   ,  7.   ,  0.965],\n",
    "    [32.   ,  8.   ,  0.962],\n",
    "    [32.   ,  9.   ,  0.989],\n",
    "    [32.   , 10.   ,  0.976],\n",
    "    [32.   , 11.   ,  1.003],\n",
    "    [32.   , 12.   ,  1.02 ],\n",
    "    [33.   ,  1.   ,  0.891],\n",
    "    [33.   ,  2.   ,  0.888],\n",
    "    [33.   ,  3.   ,  0.975],\n",
    "    [33.   ,  4.   ,  0.932],\n",
    "    [33.   ,  5.   ,  0.929],\n",
    "    [33.   ,  6.   ,  0.976],\n",
    "    [33.   ,  7.   ,  0.983],\n",
    "    [33.   ,  8.   ,  0.97 ],\n",
    "    [33.   ,  9.   ,  0.957],\n",
    "    [33.   , 10.   ,  1.014],\n",
    "    [33.   , 11.   ,  0.981],\n",
    "    [33.   , 12.   ,  1.048],\n",
    "    [34.   ,  1.   ,  0.929],\n",
    "    [34.   ,  2.   ,  0.986],\n",
    "    [34.   ,  3.   ,  0.943],\n",
    "    [34.   ,  4.   ,  0.93 ],\n",
    "    [34.   ,  5.   ,  0.967],\n",
    "    [34.   ,  6.   ,  0.974],\n",
    "    [34.   ,  7.   ,  1.021],\n",
    "    [34.   ,  8.   ,  0.978],\n",
    "    [34.   ,  9.   ,  1.045],\n",
    "    [34.   , 10.   ,  0.972],\n",
    "    [34.   , 11.   ,  0.979],\n",
    "    [34.   , 12.   ,  0.986],\n",
    "    [35.   ,  1.   ,  1.027],\n",
    "    [35.   ,  2.   ,  0.964],\n",
    "    [35.   ,  3.   ,  1.041],\n",
    "    [35.   ,  4.   ,  1.048],\n",
    "    [35.   ,  5.   ,  1.065],\n",
    "    [35.   ,  6.   ,  0.972],\n",
    "    [35.   ,  7.   ,  0.979],\n",
    "    [35.   ,  8.   ,  1.036],\n",
    "    [35.   ,  9.   ,  0.993],\n",
    "    [35.   , 10.   ,  1.07 ],\n",
    "    [35.   , 11.   ,  1.017],\n",
    "    [35.   , 12.   ,  1.014],\n",
    "    [36.   ,  1.   ,  1.055],\n",
    "    [36.   ,  2.   ,  1.052],\n",
    "    [36.   ,  3.   ,  1.059],\n",
    "    [36.   ,  4.   ,  0.986],\n",
    "    [36.   ,  5.   ,  1.023],\n",
    "    [36.   ,  6.   ,  1.05 ],\n",
    "    [36.   ,  7.   ,  1.047],\n",
    "    [36.   ,  8.   ,  1.114],\n",
    "    [36.   ,  9.   ,  1.081],\n",
    "    [36.   , 10.   ,  1.088],\n",
    "    [36.   , 11.   ,  1.045],\n",
    "    [36.   , 12.   ,  1.112],\n",
    "    [37.   ,  1.   ,  1.003],\n",
    "    [37.   ,  2.   ,  1.1  ],\n",
    "    [37.   ,  3.   ,  1.077],\n",
    "    [37.   ,  4.   ,  1.054],\n",
    "    [37.   ,  5.   ,  1.021],\n",
    "    [37.   ,  6.   ,  1.048],\n",
    "    [37.   ,  7.   ,  1.055],\n",
    "    [37.   ,  8.   ,  1.112],\n",
    "    [37.   ,  9.   ,  1.109],\n",
    "    [37.   , 10.   ,  1.136],\n",
    "    [37.   , 11.   ,  1.153],\n",
    "    [37.   , 12.   ,  1.16 ],\n",
    "    [38.   ,  1.   ,  1.061],\n",
    "    [38.   ,  2.   ,  1.128],\n",
    "    [38.   ,  3.   ,  1.135],\n",
    "    [38.   ,  4.   ,  1.042],\n",
    "    [38.   ,  5.   ,  1.079],\n",
    "    [38.   ,  6.   ,  1.056],\n",
    "    [38.   ,  7.   ,  1.133],\n",
    "    [38.   ,  8.   ,  1.08 ],\n",
    "    [38.   ,  9.   ,  1.087],\n",
    "    [38.   , 10.   ,  1.184],\n",
    "    [38.   , 11.   ,  1.191],\n",
    "    [38.   , 12.   ,  1.178],\n",
    "    [39.   ,  1.   ,  1.049],\n",
    "    [39.   ,  2.   ,  1.056],\n",
    "    [39.   ,  3.   ,  1.133],\n",
    "    [39.   ,  4.   ,  1.15 ],\n",
    "    [39.   ,  5.   ,  1.127],\n",
    "    [39.   ,  6.   ,  1.134],\n",
    "    [39.   ,  7.   ,  1.101],\n",
    "    [39.   ,  8.   ,  1.188],\n",
    "    [39.   ,  9.   ,  1.145],\n",
    "    [39.   , 10.   ,  1.122],\n",
    "    [39.   , 11.   ,  1.219],\n",
    "    [39.   , 12.   ,  1.206],\n",
    "    [40.   ,  1.   ,  1.107],\n",
    "    [40.   ,  2.   ,  1.134],\n",
    "    [40.   ,  3.   ,  1.161],\n",
    "    [40.   ,  4.   ,  1.108],\n",
    "    [40.   ,  5.   ,  1.135],\n",
    "    [40.   ,  6.   ,  1.182],\n",
    "    [40.   ,  7.   ,  1.179],\n",
    "    [40.   ,  8.   ,  1.226],\n",
    "    [40.   ,  9.   ,  1.143],\n",
    "    [40.   , 10.   ,  1.18 ],\n",
    "    [40.   , 11.   ,  1.237],\n",
    "    [40.   , 12.   ,  1.194]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying we sliced $X$ correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28.,  1.],\n",
       "       [28.,  2.],\n",
       "       [28.,  3.],\n",
       "       [28.,  4.],\n",
       "       [28.,  5.],\n",
       "       [28.,  6.],\n",
       "       [28.,  7.],\n",
       "       [28.,  8.],\n",
       "       [28.,  9.],\n",
       "       [28., 10.],\n",
       "       [28., 11.],\n",
       "       [28., 12.],\n",
       "       [29.,  1.],\n",
       "       [29.,  2.],\n",
       "       [29.,  3.],\n",
       "       [29.,  4.],\n",
       "       [29.,  5.],\n",
       "       [29.,  6.],\n",
       "       [29.,  7.],\n",
       "       [29.,  8.],\n",
       "       [29.,  9.],\n",
       "       [29., 10.],\n",
       "       [29., 11.],\n",
       "       [29., 12.],\n",
       "       [30.,  1.],\n",
       "       [30.,  2.],\n",
       "       [30.,  3.],\n",
       "       [30.,  4.],\n",
       "       [30.,  5.],\n",
       "       [30.,  6.],\n",
       "       [30.,  7.],\n",
       "       [30.,  8.],\n",
       "       [30.,  9.],\n",
       "       [30., 10.],\n",
       "       [30., 11.],\n",
       "       [30., 12.],\n",
       "       [31.,  1.],\n",
       "       [31.,  2.],\n",
       "       [31.,  3.],\n",
       "       [31.,  4.],\n",
       "       [31.,  5.],\n",
       "       [31.,  6.],\n",
       "       [31.,  7.],\n",
       "       [31.,  8.],\n",
       "       [31.,  9.],\n",
       "       [31., 10.],\n",
       "       [31., 11.],\n",
       "       [31., 12.],\n",
       "       [32.,  1.],\n",
       "       [32.,  2.],\n",
       "       [32.,  3.],\n",
       "       [32.,  4.],\n",
       "       [32.,  5.],\n",
       "       [32.,  6.],\n",
       "       [32.,  7.],\n",
       "       [32.,  8.],\n",
       "       [32.,  9.],\n",
       "       [32., 10.],\n",
       "       [32., 11.],\n",
       "       [32., 12.],\n",
       "       [33.,  1.],\n",
       "       [33.,  2.],\n",
       "       [33.,  3.],\n",
       "       [33.,  4.],\n",
       "       [33.,  5.],\n",
       "       [33.,  6.],\n",
       "       [33.,  7.],\n",
       "       [33.,  8.],\n",
       "       [33.,  9.],\n",
       "       [33., 10.],\n",
       "       [33., 11.],\n",
       "       [33., 12.],\n",
       "       [34.,  1.],\n",
       "       [34.,  2.],\n",
       "       [34.,  3.],\n",
       "       [34.,  4.],\n",
       "       [34.,  5.],\n",
       "       [34.,  6.],\n",
       "       [34.,  7.],\n",
       "       [34.,  8.],\n",
       "       [34.,  9.],\n",
       "       [34., 10.],\n",
       "       [34., 11.],\n",
       "       [34., 12.],\n",
       "       [35.,  1.],\n",
       "       [35.,  2.],\n",
       "       [35.,  3.],\n",
       "       [35.,  4.],\n",
       "       [35.,  5.],\n",
       "       [35.,  6.],\n",
       "       [35.,  7.],\n",
       "       [35.,  8.],\n",
       "       [35.,  9.],\n",
       "       [35., 10.],\n",
       "       [35., 11.],\n",
       "       [35., 12.],\n",
       "       [36.,  1.],\n",
       "       [36.,  2.],\n",
       "       [36.,  3.],\n",
       "       [36.,  4.],\n",
       "       [36.,  5.],\n",
       "       [36.,  6.],\n",
       "       [36.,  7.],\n",
       "       [36.,  8.],\n",
       "       [36.,  9.],\n",
       "       [36., 10.],\n",
       "       [36., 11.],\n",
       "       [36., 12.],\n",
       "       [37.,  1.],\n",
       "       [37.,  2.],\n",
       "       [37.,  3.],\n",
       "       [37.,  4.],\n",
       "       [37.,  5.],\n",
       "       [37.,  6.],\n",
       "       [37.,  7.],\n",
       "       [37.,  8.],\n",
       "       [37.,  9.],\n",
       "       [37., 10.],\n",
       "       [37., 11.],\n",
       "       [37., 12.],\n",
       "       [38.,  1.],\n",
       "       [38.,  2.],\n",
       "       [38.,  3.],\n",
       "       [38.,  4.],\n",
       "       [38.,  5.],\n",
       "       [38.,  6.],\n",
       "       [38.,  7.],\n",
       "       [38.,  8.],\n",
       "       [38.,  9.],\n",
       "       [38., 10.],\n",
       "       [38., 11.],\n",
       "       [38., 12.],\n",
       "       [39.,  1.],\n",
       "       [39.,  2.],\n",
       "       [39.,  3.],\n",
       "       [39.,  4.],\n",
       "       [39.,  5.],\n",
       "       [39.,  6.],\n",
       "       [39.,  7.],\n",
       "       [39.,  8.],\n",
       "       [39.,  9.],\n",
       "       [39., 10.],\n",
       "       [39., 11.],\n",
       "       [39., 12.],\n",
       "       [40.,  1.],\n",
       "       [40.,  2.],\n",
       "       [40.,  3.],\n",
       "       [40.,  4.],\n",
       "       [40.,  5.],\n",
       "       [40.,  6.],\n",
       "       [40.,  7.],\n",
       "       [40.,  8.],\n",
       "       [40.,  9.],\n",
       "       [40., 10.],\n",
       "       [40., 11.],\n",
       "       [40., 12.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[:, 0:2]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying we sliced $y$ correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.801],\n",
       "       [0.758],\n",
       "       [0.785],\n",
       "       [0.862],\n",
       "       [0.799],\n",
       "       [0.836],\n",
       "       [0.783],\n",
       "       [0.8  ],\n",
       "       [0.887],\n",
       "       [0.904],\n",
       "       [0.831],\n",
       "       [0.848],\n",
       "       [0.839],\n",
       "       [0.836],\n",
       "       [0.803],\n",
       "       [0.83 ],\n",
       "       [0.877],\n",
       "       [0.884],\n",
       "       [0.871],\n",
       "       [0.888],\n",
       "       [0.915],\n",
       "       [0.912],\n",
       "       [0.859],\n",
       "       [0.876],\n",
       "       [0.857],\n",
       "       [0.854],\n",
       "       [0.841],\n",
       "       [0.818],\n",
       "       [0.825],\n",
       "       [0.852],\n",
       "       [0.849],\n",
       "       [0.876],\n",
       "       [0.873],\n",
       "       [0.88 ],\n",
       "       [0.947],\n",
       "       [0.964],\n",
       "       [0.825],\n",
       "       [0.912],\n",
       "       [0.909],\n",
       "       [0.856],\n",
       "       [0.893],\n",
       "       [0.91 ],\n",
       "       [0.867],\n",
       "       [0.974],\n",
       "       [0.921],\n",
       "       [0.888],\n",
       "       [0.905],\n",
       "       [0.952],\n",
       "       [0.943],\n",
       "       [0.88 ],\n",
       "       [0.877],\n",
       "       [0.904],\n",
       "       [0.891],\n",
       "       [0.898],\n",
       "       [0.965],\n",
       "       [0.962],\n",
       "       [0.989],\n",
       "       [0.976],\n",
       "       [1.003],\n",
       "       [1.02 ],\n",
       "       [0.891],\n",
       "       [0.888],\n",
       "       [0.975],\n",
       "       [0.932],\n",
       "       [0.929],\n",
       "       [0.976],\n",
       "       [0.983],\n",
       "       [0.97 ],\n",
       "       [0.957],\n",
       "       [1.014],\n",
       "       [0.981],\n",
       "       [1.048],\n",
       "       [0.929],\n",
       "       [0.986],\n",
       "       [0.943],\n",
       "       [0.93 ],\n",
       "       [0.967],\n",
       "       [0.974],\n",
       "       [1.021],\n",
       "       [0.978],\n",
       "       [1.045],\n",
       "       [0.972],\n",
       "       [0.979],\n",
       "       [0.986],\n",
       "       [1.027],\n",
       "       [0.964],\n",
       "       [1.041],\n",
       "       [1.048],\n",
       "       [1.065],\n",
       "       [0.972],\n",
       "       [0.979],\n",
       "       [1.036],\n",
       "       [0.993],\n",
       "       [1.07 ],\n",
       "       [1.017],\n",
       "       [1.014],\n",
       "       [1.055],\n",
       "       [1.052],\n",
       "       [1.059],\n",
       "       [0.986],\n",
       "       [1.023],\n",
       "       [1.05 ],\n",
       "       [1.047],\n",
       "       [1.114],\n",
       "       [1.081],\n",
       "       [1.088],\n",
       "       [1.045],\n",
       "       [1.112],\n",
       "       [1.003],\n",
       "       [1.1  ],\n",
       "       [1.077],\n",
       "       [1.054],\n",
       "       [1.021],\n",
       "       [1.048],\n",
       "       [1.055],\n",
       "       [1.112],\n",
       "       [1.109],\n",
       "       [1.136],\n",
       "       [1.153],\n",
       "       [1.16 ],\n",
       "       [1.061],\n",
       "       [1.128],\n",
       "       [1.135],\n",
       "       [1.042],\n",
       "       [1.079],\n",
       "       [1.056],\n",
       "       [1.133],\n",
       "       [1.08 ],\n",
       "       [1.087],\n",
       "       [1.184],\n",
       "       [1.191],\n",
       "       [1.178],\n",
       "       [1.049],\n",
       "       [1.056],\n",
       "       [1.133],\n",
       "       [1.15 ],\n",
       "       [1.127],\n",
       "       [1.134],\n",
       "       [1.101],\n",
       "       [1.188],\n",
       "       [1.145],\n",
       "       [1.122],\n",
       "       [1.219],\n",
       "       [1.206],\n",
       "       [1.107],\n",
       "       [1.134],\n",
       "       [1.161],\n",
       "       [1.108],\n",
       "       [1.135],\n",
       "       [1.182],\n",
       "       [1.179],\n",
       "       [1.226],\n",
       "       [1.143],\n",
       "       [1.18 ],\n",
       "       [1.237],\n",
       "       [1.194]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data[:, [-1]]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the lowest and highest of each of the following:\n",
    "- certification score\n",
    "- years experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.,  1.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first the lowest of each\n",
    "np.min(X, axis=0) # 0 = x-axis, 1 = y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40., 12.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then the highest of each\n",
    "np.max(X, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we scale using Scikit-learn's scaler, which is easier.  We can also use numpy's vectorization, that's one less library to learn.\n",
    "\n",
    "Note that:\n",
    "- for certification scores of `40`, they become `1`s, `28` become `0`s.\n",
    "- for years experience of `1`, they become `0`s, `12` becomes `1`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28.,  1.],\n",
       "       [28.,  2.],\n",
       "       [28.,  3.],\n",
       "       [28.,  4.],\n",
       "       [28.,  5.],\n",
       "       [28.,  6.],\n",
       "       [28.,  7.],\n",
       "       [28.,  8.],\n",
       "       [28.,  9.],\n",
       "       [28., 10.],\n",
       "       [28., 11.],\n",
       "       [28., 12.],\n",
       "       [29.,  1.],\n",
       "       [29.,  2.],\n",
       "       [29.,  3.],\n",
       "       [29.,  4.],\n",
       "       [29.,  5.],\n",
       "       [29.,  6.],\n",
       "       [29.,  7.],\n",
       "       [29.,  8.],\n",
       "       [29.,  9.],\n",
       "       [29., 10.],\n",
       "       [29., 11.],\n",
       "       [29., 12.],\n",
       "       [30.,  1.],\n",
       "       [30.,  2.],\n",
       "       [30.,  3.],\n",
       "       [30.,  4.],\n",
       "       [30.,  5.],\n",
       "       [30.,  6.],\n",
       "       [30.,  7.],\n",
       "       [30.,  8.],\n",
       "       [30.,  9.],\n",
       "       [30., 10.],\n",
       "       [30., 11.],\n",
       "       [30., 12.],\n",
       "       [31.,  1.],\n",
       "       [31.,  2.],\n",
       "       [31.,  3.],\n",
       "       [31.,  4.],\n",
       "       [31.,  5.],\n",
       "       [31.,  6.],\n",
       "       [31.,  7.],\n",
       "       [31.,  8.],\n",
       "       [31.,  9.],\n",
       "       [31., 10.],\n",
       "       [31., 11.],\n",
       "       [31., 12.],\n",
       "       [32.,  1.],\n",
       "       [32.,  2.],\n",
       "       [32.,  3.],\n",
       "       [32.,  4.],\n",
       "       [32.,  5.],\n",
       "       [32.,  6.],\n",
       "       [32.,  7.],\n",
       "       [32.,  8.],\n",
       "       [32.,  9.],\n",
       "       [32., 10.],\n",
       "       [32., 11.],\n",
       "       [32., 12.],\n",
       "       [33.,  1.],\n",
       "       [33.,  2.],\n",
       "       [33.,  3.],\n",
       "       [33.,  4.],\n",
       "       [33.,  5.],\n",
       "       [33.,  6.],\n",
       "       [33.,  7.],\n",
       "       [33.,  8.],\n",
       "       [33.,  9.],\n",
       "       [33., 10.],\n",
       "       [33., 11.],\n",
       "       [33., 12.],\n",
       "       [34.,  1.],\n",
       "       [34.,  2.],\n",
       "       [34.,  3.],\n",
       "       [34.,  4.],\n",
       "       [34.,  5.],\n",
       "       [34.,  6.],\n",
       "       [34.,  7.],\n",
       "       [34.,  8.],\n",
       "       [34.,  9.],\n",
       "       [34., 10.],\n",
       "       [34., 11.],\n",
       "       [34., 12.],\n",
       "       [35.,  1.],\n",
       "       [35.,  2.],\n",
       "       [35.,  3.],\n",
       "       [35.,  4.],\n",
       "       [35.,  5.],\n",
       "       [35.,  6.],\n",
       "       [35.,  7.],\n",
       "       [35.,  8.],\n",
       "       [35.,  9.],\n",
       "       [35., 10.],\n",
       "       [35., 11.],\n",
       "       [35., 12.],\n",
       "       [36.,  1.],\n",
       "       [36.,  2.],\n",
       "       [36.,  3.],\n",
       "       [36.,  4.],\n",
       "       [36.,  5.],\n",
       "       [36.,  6.],\n",
       "       [36.,  7.],\n",
       "       [36.,  8.],\n",
       "       [36.,  9.],\n",
       "       [36., 10.],\n",
       "       [36., 11.],\n",
       "       [36., 12.],\n",
       "       [37.,  1.],\n",
       "       [37.,  2.],\n",
       "       [37.,  3.],\n",
       "       [37.,  4.],\n",
       "       [37.,  5.],\n",
       "       [37.,  6.],\n",
       "       [37.,  7.],\n",
       "       [37.,  8.],\n",
       "       [37.,  9.],\n",
       "       [37., 10.],\n",
       "       [37., 11.],\n",
       "       [37., 12.],\n",
       "       [38.,  1.],\n",
       "       [38.,  2.],\n",
       "       [38.,  3.],\n",
       "       [38.,  4.],\n",
       "       [38.,  5.],\n",
       "       [38.,  6.],\n",
       "       [38.,  7.],\n",
       "       [38.,  8.],\n",
       "       [38.,  9.],\n",
       "       [38., 10.],\n",
       "       [38., 11.],\n",
       "       [38., 12.],\n",
       "       [39.,  1.],\n",
       "       [39.,  2.],\n",
       "       [39.,  3.],\n",
       "       [39.,  4.],\n",
       "       [39.,  5.],\n",
       "       [39.,  6.],\n",
       "       [39.,  7.],\n",
       "       [39.,  8.],\n",
       "       [39.,  9.],\n",
       "       [39., 10.],\n",
       "       [39., 11.],\n",
       "       [39., 12.],\n",
       "       [40.,  1.],\n",
       "       [40.,  2.],\n",
       "       [40.,  3.],\n",
       "       [40.,  4.],\n",
       "       [40.,  5.],\n",
       "       [40.,  6.],\n",
       "       [40.,  7.],\n",
       "       [40.,  8.],\n",
       "       [40.,  9.],\n",
       "       [40., 10.],\n",
       "       [40., 11.],\n",
       "       [40., 12.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_norm = scaler.fit_transform(X)\n",
    "\n",
    "# Showing the normalized values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   ],\n",
       "       [0.   , 0.091],\n",
       "       [0.   , 0.182],\n",
       "       [0.   , 0.273],\n",
       "       [0.   , 0.364],\n",
       "       [0.   , 0.455],\n",
       "       [0.   , 0.545],\n",
       "       [0.   , 0.636],\n",
       "       [0.   , 0.727],\n",
       "       [0.   , 0.818],\n",
       "       [0.   , 0.909],\n",
       "       [0.   , 1.   ],\n",
       "       [0.083, 0.   ],\n",
       "       [0.083, 0.091],\n",
       "       [0.083, 0.182],\n",
       "       [0.083, 0.273],\n",
       "       [0.083, 0.364],\n",
       "       [0.083, 0.455],\n",
       "       [0.083, 0.545],\n",
       "       [0.083, 0.636],\n",
       "       [0.083, 0.727],\n",
       "       [0.083, 0.818],\n",
       "       [0.083, 0.909],\n",
       "       [0.083, 1.   ],\n",
       "       [0.167, 0.   ],\n",
       "       [0.167, 0.091],\n",
       "       [0.167, 0.182],\n",
       "       [0.167, 0.273],\n",
       "       [0.167, 0.364],\n",
       "       [0.167, 0.455],\n",
       "       [0.167, 0.545],\n",
       "       [0.167, 0.636],\n",
       "       [0.167, 0.727],\n",
       "       [0.167, 0.818],\n",
       "       [0.167, 0.909],\n",
       "       [0.167, 1.   ],\n",
       "       [0.25 , 0.   ],\n",
       "       [0.25 , 0.091],\n",
       "       [0.25 , 0.182],\n",
       "       [0.25 , 0.273],\n",
       "       [0.25 , 0.364],\n",
       "       [0.25 , 0.455],\n",
       "       [0.25 , 0.545],\n",
       "       [0.25 , 0.636],\n",
       "       [0.25 , 0.727],\n",
       "       [0.25 , 0.818],\n",
       "       [0.25 , 0.909],\n",
       "       [0.25 , 1.   ],\n",
       "       [0.333, 0.   ],\n",
       "       [0.333, 0.091],\n",
       "       [0.333, 0.182],\n",
       "       [0.333, 0.273],\n",
       "       [0.333, 0.364],\n",
       "       [0.333, 0.455],\n",
       "       [0.333, 0.545],\n",
       "       [0.333, 0.636],\n",
       "       [0.333, 0.727],\n",
       "       [0.333, 0.818],\n",
       "       [0.333, 0.909],\n",
       "       [0.333, 1.   ],\n",
       "       [0.417, 0.   ],\n",
       "       [0.417, 0.091],\n",
       "       [0.417, 0.182],\n",
       "       [0.417, 0.273],\n",
       "       [0.417, 0.364],\n",
       "       [0.417, 0.455],\n",
       "       [0.417, 0.545],\n",
       "       [0.417, 0.636],\n",
       "       [0.417, 0.727],\n",
       "       [0.417, 0.818],\n",
       "       [0.417, 0.909],\n",
       "       [0.417, 1.   ],\n",
       "       [0.5  , 0.   ],\n",
       "       [0.5  , 0.091],\n",
       "       [0.5  , 0.182],\n",
       "       [0.5  , 0.273],\n",
       "       [0.5  , 0.364],\n",
       "       [0.5  , 0.455],\n",
       "       [0.5  , 0.545],\n",
       "       [0.5  , 0.636],\n",
       "       [0.5  , 0.727],\n",
       "       [0.5  , 0.818],\n",
       "       [0.5  , 0.909],\n",
       "       [0.5  , 1.   ],\n",
       "       [0.583, 0.   ],\n",
       "       [0.583, 0.091],\n",
       "       [0.583, 0.182],\n",
       "       [0.583, 0.273],\n",
       "       [0.583, 0.364],\n",
       "       [0.583, 0.455],\n",
       "       [0.583, 0.545],\n",
       "       [0.583, 0.636],\n",
       "       [0.583, 0.727],\n",
       "       [0.583, 0.818],\n",
       "       [0.583, 0.909],\n",
       "       [0.583, 1.   ],\n",
       "       [0.667, 0.   ],\n",
       "       [0.667, 0.091],\n",
       "       [0.667, 0.182],\n",
       "       [0.667, 0.273],\n",
       "       [0.667, 0.364],\n",
       "       [0.667, 0.455],\n",
       "       [0.667, 0.545],\n",
       "       [0.667, 0.636],\n",
       "       [0.667, 0.727],\n",
       "       [0.667, 0.818],\n",
       "       [0.667, 0.909],\n",
       "       [0.667, 1.   ],\n",
       "       [0.75 , 0.   ],\n",
       "       [0.75 , 0.091],\n",
       "       [0.75 , 0.182],\n",
       "       [0.75 , 0.273],\n",
       "       [0.75 , 0.364],\n",
       "       [0.75 , 0.455],\n",
       "       [0.75 , 0.545],\n",
       "       [0.75 , 0.636],\n",
       "       [0.75 , 0.727],\n",
       "       [0.75 , 0.818],\n",
       "       [0.75 , 0.909],\n",
       "       [0.75 , 1.   ],\n",
       "       [0.833, 0.   ],\n",
       "       [0.833, 0.091],\n",
       "       [0.833, 0.182],\n",
       "       [0.833, 0.273],\n",
       "       [0.833, 0.364],\n",
       "       [0.833, 0.455],\n",
       "       [0.833, 0.545],\n",
       "       [0.833, 0.636],\n",
       "       [0.833, 0.727],\n",
       "       [0.833, 0.818],\n",
       "       [0.833, 0.909],\n",
       "       [0.833, 1.   ],\n",
       "       [0.917, 0.   ],\n",
       "       [0.917, 0.091],\n",
       "       [0.917, 0.182],\n",
       "       [0.917, 0.273],\n",
       "       [0.917, 0.364],\n",
       "       [0.917, 0.455],\n",
       "       [0.917, 0.545],\n",
       "       [0.917, 0.636],\n",
       "       [0.917, 0.727],\n",
       "       [0.917, 0.818],\n",
       "       [0.917, 0.909],\n",
       "       [0.917, 1.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.091],\n",
       "       [1.   , 0.182],\n",
       "       [1.   , 0.273],\n",
       "       [1.   , 0.364],\n",
       "       [1.   , 0.455],\n",
       "       [1.   , 0.545],\n",
       "       [1.   , 0.636],\n",
       "       [1.   , 0.727],\n",
       "       [1.   , 0.818],\n",
       "       [1.   , 0.909],\n",
       "       [1.   , 1.   ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and the normalized ones\n",
    "X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile and train your model here\n",
    "\n",
    "# <YOUR TURN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28.   ,  1.   ,  0.801],\n",
       "       [28.   ,  2.   ,  0.758],\n",
       "       [28.   ,  3.   ,  0.785],\n",
       "       [28.   ,  4.   ,  0.862],\n",
       "       [28.   ,  5.   ,  0.799],\n",
       "       [28.   ,  6.   ,  0.836],\n",
       "       [28.   ,  7.   ,  0.783],\n",
       "       [28.   ,  8.   ,  0.8  ],\n",
       "       [28.   ,  9.   ,  0.887],\n",
       "       [28.   , 10.   ,  0.904],\n",
       "       [28.   , 11.   ,  0.831],\n",
       "       [28.   , 12.   ,  0.848],\n",
       "       [29.   ,  1.   ,  0.839],\n",
       "       [29.   ,  2.   ,  0.836],\n",
       "       [29.   ,  3.   ,  0.803],\n",
       "       [29.   ,  4.   ,  0.83 ],\n",
       "       [29.   ,  5.   ,  0.877],\n",
       "       [29.   ,  6.   ,  0.884],\n",
       "       [29.   ,  7.   ,  0.871],\n",
       "       [29.   ,  8.   ,  0.888],\n",
       "       [29.   ,  9.   ,  0.915],\n",
       "       [29.   , 10.   ,  0.912],\n",
       "       [29.   , 11.   ,  0.859],\n",
       "       [29.   , 12.   ,  0.876],\n",
       "       [30.   ,  1.   ,  0.857],\n",
       "       [30.   ,  2.   ,  0.854],\n",
       "       [30.   ,  3.   ,  0.841],\n",
       "       [30.   ,  4.   ,  0.818],\n",
       "       [30.   ,  5.   ,  0.825],\n",
       "       [30.   ,  6.   ,  0.852],\n",
       "       [30.   ,  7.   ,  0.849],\n",
       "       [30.   ,  8.   ,  0.876],\n",
       "       [30.   ,  9.   ,  0.873],\n",
       "       [30.   , 10.   ,  0.88 ],\n",
       "       [30.   , 11.   ,  0.947],\n",
       "       [30.   , 12.   ,  0.964],\n",
       "       [31.   ,  1.   ,  0.825],\n",
       "       [31.   ,  2.   ,  0.912],\n",
       "       [31.   ,  3.   ,  0.909],\n",
       "       [31.   ,  4.   ,  0.856],\n",
       "       [31.   ,  5.   ,  0.893],\n",
       "       [31.   ,  6.   ,  0.91 ],\n",
       "       [31.   ,  7.   ,  0.867],\n",
       "       [31.   ,  8.   ,  0.974],\n",
       "       [31.   ,  9.   ,  0.921],\n",
       "       [31.   , 10.   ,  0.888],\n",
       "       [31.   , 11.   ,  0.905],\n",
       "       [31.   , 12.   ,  0.952],\n",
       "       [32.   ,  1.   ,  0.943],\n",
       "       [32.   ,  2.   ,  0.88 ],\n",
       "       [32.   ,  3.   ,  0.877],\n",
       "       [32.   ,  4.   ,  0.904],\n",
       "       [32.   ,  5.   ,  0.891],\n",
       "       [32.   ,  6.   ,  0.898],\n",
       "       [32.   ,  7.   ,  0.965],\n",
       "       [32.   ,  8.   ,  0.962],\n",
       "       [32.   ,  9.   ,  0.989],\n",
       "       [32.   , 10.   ,  0.976],\n",
       "       [32.   , 11.   ,  1.003],\n",
       "       [32.   , 12.   ,  1.02 ],\n",
       "       [33.   ,  1.   ,  0.891],\n",
       "       [33.   ,  2.   ,  0.888],\n",
       "       [33.   ,  3.   ,  0.975],\n",
       "       [33.   ,  4.   ,  0.932],\n",
       "       [33.   ,  5.   ,  0.929],\n",
       "       [33.   ,  6.   ,  0.976],\n",
       "       [33.   ,  7.   ,  0.983],\n",
       "       [33.   ,  8.   ,  0.97 ],\n",
       "       [33.   ,  9.   ,  0.957],\n",
       "       [33.   , 10.   ,  1.014],\n",
       "       [33.   , 11.   ,  0.981],\n",
       "       [33.   , 12.   ,  1.048],\n",
       "       [34.   ,  1.   ,  0.929],\n",
       "       [34.   ,  2.   ,  0.986],\n",
       "       [34.   ,  3.   ,  0.943],\n",
       "       [34.   ,  4.   ,  0.93 ],\n",
       "       [34.   ,  5.   ,  0.967],\n",
       "       [34.   ,  6.   ,  0.974],\n",
       "       [34.   ,  7.   ,  1.021],\n",
       "       [34.   ,  8.   ,  0.978],\n",
       "       [34.   ,  9.   ,  1.045],\n",
       "       [34.   , 10.   ,  0.972],\n",
       "       [34.   , 11.   ,  0.979],\n",
       "       [34.   , 12.   ,  0.986],\n",
       "       [35.   ,  1.   ,  1.027],\n",
       "       [35.   ,  2.   ,  0.964],\n",
       "       [35.   ,  3.   ,  1.041],\n",
       "       [35.   ,  4.   ,  1.048],\n",
       "       [35.   ,  5.   ,  1.065],\n",
       "       [35.   ,  6.   ,  0.972],\n",
       "       [35.   ,  7.   ,  0.979],\n",
       "       [35.   ,  8.   ,  1.036],\n",
       "       [35.   ,  9.   ,  0.993],\n",
       "       [35.   , 10.   ,  1.07 ],\n",
       "       [35.   , 11.   ,  1.017],\n",
       "       [35.   , 12.   ,  1.014],\n",
       "       [36.   ,  1.   ,  1.055],\n",
       "       [36.   ,  2.   ,  1.052],\n",
       "       [36.   ,  3.   ,  1.059],\n",
       "       [36.   ,  4.   ,  0.986],\n",
       "       [36.   ,  5.   ,  1.023],\n",
       "       [36.   ,  6.   ,  1.05 ],\n",
       "       [36.   ,  7.   ,  1.047],\n",
       "       [36.   ,  8.   ,  1.114],\n",
       "       [36.   ,  9.   ,  1.081],\n",
       "       [36.   , 10.   ,  1.088],\n",
       "       [36.   , 11.   ,  1.045],\n",
       "       [36.   , 12.   ,  1.112],\n",
       "       [37.   ,  1.   ,  1.003],\n",
       "       [37.   ,  2.   ,  1.1  ],\n",
       "       [37.   ,  3.   ,  1.077],\n",
       "       [37.   ,  4.   ,  1.054],\n",
       "       [37.   ,  5.   ,  1.021],\n",
       "       [37.   ,  6.   ,  1.048],\n",
       "       [37.   ,  7.   ,  1.055],\n",
       "       [37.   ,  8.   ,  1.112],\n",
       "       [37.   ,  9.   ,  1.109],\n",
       "       [37.   , 10.   ,  1.136],\n",
       "       [37.   , 11.   ,  1.153],\n",
       "       [37.   , 12.   ,  1.16 ],\n",
       "       [38.   ,  1.   ,  1.061],\n",
       "       [38.   ,  2.   ,  1.128],\n",
       "       [38.   ,  3.   ,  1.135],\n",
       "       [38.   ,  4.   ,  1.042],\n",
       "       [38.   ,  5.   ,  1.079],\n",
       "       [38.   ,  6.   ,  1.056],\n",
       "       [38.   ,  7.   ,  1.133],\n",
       "       [38.   ,  8.   ,  1.08 ],\n",
       "       [38.   ,  9.   ,  1.087],\n",
       "       [38.   , 10.   ,  1.184],\n",
       "       [38.   , 11.   ,  1.191],\n",
       "       [38.   , 12.   ,  1.178],\n",
       "       [39.   ,  1.   ,  1.049],\n",
       "       [39.   ,  2.   ,  1.056],\n",
       "       [39.   ,  3.   ,  1.133],\n",
       "       [39.   ,  4.   ,  1.15 ],\n",
       "       [39.   ,  5.   ,  1.127],\n",
       "       [39.   ,  6.   ,  1.134],\n",
       "       [39.   ,  7.   ,  1.101],\n",
       "       [39.   ,  8.   ,  1.188],\n",
       "       [39.   ,  9.   ,  1.145],\n",
       "       [39.   , 10.   ,  1.122],\n",
       "       [39.   , 11.   ,  1.219],\n",
       "       [39.   , 12.   ,  1.206],\n",
       "       [40.   ,  1.   ,  1.107],\n",
       "       [40.   ,  2.   ,  1.134],\n",
       "       [40.   ,  3.   ,  1.161],\n",
       "       [40.   ,  4.   ,  1.108],\n",
       "       [40.   ,  5.   ,  1.135],\n",
       "       [40.   ,  6.   ,  1.182],\n",
       "       [40.   ,  7.   ,  1.179],\n",
       "       [40.   ,  8.   ,  1.226],\n",
       "       [40.   ,  9.   ,  1.143],\n",
       "       [40.   , 10.   ,  1.18 ],\n",
       "       [40.   , 11.   ,  1.237],\n",
       "       [40.   , 12.   ,  1.194]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing our training data again, so we can compare\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much will we offer?\n",
    "- another candidate barely passing, with 12 years exp\n",
    "- another _\"kabit\"_, but a 15 year veteran?\n",
    "  * we never had a 15 year veteran apply before\n",
    "- barely passing also, and with only half a year experience?\n",
    "  * never had an almost fresh-grad so far\n",
    "- perfect score, 15 years experience\n",
    "- perfect score, 12 years experience, like the guy offered $119.4k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.   ,  1.   ],\n",
       "       [ 0.   ,  1.273],\n",
       "       [ 0.   , -0.045],\n",
       "       [ 1.   ,  1.273],\n",
       "       [ 1.   ,  1.   ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_input = scaler.transform(np.array([\n",
    "    [28, 12], \n",
    "    [28, 15],\n",
    "    [28, 0.5],\n",
    "    [40, 15],\n",
    "    [40, 12]\n",
    "]))\n",
    "\n",
    "scaled_input # the -0.045 is because 0.5 is lower than the lowest years exp earlier.\n",
    "             # same with 15 years become 1.273"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <YOUR CODE TO PREDICT HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get values somewhere around:\n",
    "\n",
    "- 86,130.559\n",
    "- 89,092.261\n",
    "- 74,777.365\n",
    "- 126,128.817\n",
    "- 123,167.109\n",
    "\n",
    "😉 This dataset was artificially generated, with one entry per _\"combo\"_ of\n",
    "score and years_exp, using the formula:\n",
    "\n",
    "80% * certification_score +  \n",
    "20% * years_experience +  \n",
    "$\\pm$ (1000, 2000, 3000, 4000, 5000 Php) (random)\n",
    "\n",
    "\n",
    "The weights should be somewhere around that ratio.  I got\n",
    "$$\n",
    "  w = \\begin{bmatrix}\n",
    "    0.753 \\\\\n",
    "    0.37 \\\\\n",
    "    0.109\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "A 77:23 ratio, pretty close to 80:20 😁\n",
    "\n",
    "Using the weights to predict, when given an input, say `score = 40`, `years_exp = 15`, it would do:\n",
    "\n",
    "1. Feature Scaled 40 is `1`, feature scaled 15 is `1.273`\n",
    "2. $\\hat{y} = 0.109 \\cdot 1.273 + .37 \\cdot 1 + 0.753$  \n",
    "3. $\\hat{y} = 1.261757$\n",
    "\n",
    "but it's not yet $x100k$, so the predicted value is $126,175.7$ Php (actually 126,128.817 when our code\n",
    "is ran).\n",
    "\n",
    "The slightly bigger value from our _\"mano-mano\"_ computation is because all values are rounded off \n",
    "to 3 decimal places, but internally in our code, they're not.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d2152fd7f0bbc62aa1baff8c990435d1e2c7175d001561303988032604c11a48"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
