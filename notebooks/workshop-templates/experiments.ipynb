{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "F-n_lUVb-n7Z",
        "outputId": "ee1636ee-4b3d-4460-8572-20faf3bb5ab3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.set_printoptions(precision=3, suppress=True, linewidth=320)\n",
        "\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "id": "T9CDr_5Q_A_p"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_images.shape, training_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3btOjwzm_Vn6",
        "outputId": "0a085b57-91f3-4af2-a24c-c694fa1843ee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images.shape, test_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qhk02NA0_aB8",
        "outputId": "02eab839-1dea-4a0f-f52b-a67e2f77c2a8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 28, 28), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_images_norm = training_images / 255.0\n",
        "test_images_norm = test_images / 255.0"
      ],
      "metadata": {
        "id": "15P80pBs_gVl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_images_norm[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq46TCHp_vAG",
        "outputId": "a841daf0-8df2-449a-b0d0-c104d97c38b8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.012, 0.071, 0.071, 0.071, 0.494, 0.533, 0.686, 0.102, 0.651, 1.   , 0.969, 0.498, 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.118, 0.141, 0.369, 0.604, 0.667, 0.992, 0.992, 0.992, 0.992, 0.992, 0.882, 0.675, 0.992, 0.949, 0.765, 0.251, 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.192, 0.933, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.984, 0.365, 0.322, 0.322, 0.22 , 0.153, 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.071, 0.859, 0.992, 0.992, 0.992, 0.992, 0.992, 0.776, 0.714, 0.969, 0.945, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.314, 0.612, 0.42 , 0.992, 0.992, 0.804, 0.043, 0.   , 0.169, 0.604, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.055, 0.004, 0.604, 0.992, 0.353, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.545, 0.992, 0.745, 0.008, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.043, 0.745, 0.992, 0.275, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.137, 0.945, 0.882, 0.627, 0.424, 0.004, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.318, 0.941, 0.992, 0.992, 0.467, 0.098, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.176, 0.729, 0.992, 0.992, 0.588, 0.106, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.063, 0.365, 0.988, 0.992, 0.733, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.976, 0.992, 0.976, 0.251, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.18 , 0.51 , 0.718, 0.992, 0.992, 0.812, 0.008, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.153, 0.58 , 0.898, 0.992, 0.992, 0.992, 0.98 , 0.714, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.094, 0.447, 0.867, 0.992, 0.992, 0.992, 0.992, 0.788, 0.306, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.09 , 0.259, 0.835, 0.992, 0.992, 0.992, 0.992, 0.776, 0.318, 0.008, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.071, 0.671, 0.859, 0.992, 0.992, 0.992, 0.992, 0.765, 0.314, 0.035, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.216, 0.675, 0.886, 0.992, 0.992, 0.992, 0.992, 0.957, 0.522, 0.043, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.533, 0.992, 0.992, 0.992, 0.831, 0.529, 0.518, 0.063, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images_norm[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDl55ytjACOT",
        "outputId": "37ed7e85-087e-4b75-f4c4-1514243d37d6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.329, 0.725, 0.624, 0.592, 0.235, 0.141, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.871, 0.996, 0.996, 0.996, 0.996, 0.945, 0.776, 0.776, 0.776, 0.776, 0.776, 0.776, 0.776, 0.776, 0.667, 0.204, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.263, 0.447, 0.282, 0.447, 0.639, 0.89 , 0.996, 0.882, 0.996, 0.996, 0.996, 0.98 , 0.898, 0.996, 0.996, 0.549, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.067, 0.259, 0.055, 0.263, 0.263, 0.263, 0.231, 0.082, 0.925, 0.996, 0.416, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.325, 0.992, 0.82 , 0.071, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.086, 0.914, 1.   , 0.325, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.506, 0.996, 0.933, 0.173, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.231, 0.976, 0.996, 0.243, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.522, 0.996, 0.733, 0.02 , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.035, 0.804, 0.973, 0.227, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.494, 0.996, 0.714, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.294, 0.984, 0.941, 0.224, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.075, 0.867, 0.996, 0.651, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.012, 0.796, 0.996, 0.859, 0.137, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.149, 0.996, 0.996, 0.302, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.122, 0.878, 0.996, 0.451, 0.004, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.522, 0.996, 0.996, 0.204, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.239, 0.949, 0.996, 0.996, 0.204, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.475, 0.996, 0.996, 0.859, 0.157, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.475, 0.996, 0.812, 0.071, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
              "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_info(model):\n",
        "    model.summary()\n",
        "\n",
        "    for layer in model.layers:\n",
        "        if (isinstance(layer, keras.layers.Dense)):\n",
        "            print(f'Layer name: {layer.name};\\tActivation: {layer.activation.__name__}')\n",
        "        else:\n",
        "            print(f'Layer name: {layer.name}')\n",
        "\n",
        "    print(f'Optimizer: {model.optimizer}')\n",
        "\n",
        "def train(**kwargs):\n",
        "    # default activation for hidden layers is sigmoid\n",
        "    hidden_layers_activation = kwargs.get('hidden_layers_activation', 'sigmoid')\n",
        "    optimizer = kwargs.get('optimizer', keras.optimizers.SGD())\n",
        "    normalize = kwargs.get('normalize', True)\n",
        "    epochs = kwargs.get('epochs', 5)\n",
        "\n",
        "    # default to one hidden layer with 128 neurons\n",
        "    hidden_layers_units = kwargs.get('hidden_layers_units', [128])\n",
        "    hidden_layers = [\n",
        "        keras.layers.Dense(units, hidden_layers_activation) \n",
        "        for units in hidden_layers_units\n",
        "    ]\n",
        "\n",
        "    X_train = training_images_norm if normalize else training_images\n",
        "    X_test = test_images_norm if normalize else test_images\n",
        "\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(),\n",
        "        *hidden_layers, \n",
        "        keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer, loss=keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
        "    model.fit(X_train, training_labels, epochs=epochs)\n",
        "    show_info(model)\n",
        "\n",
        "    model.evaluate(X_test, test_labels)"
      ],
      "metadata": {
        "id": "cDV2CoyXACks"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNCeJbyaA36W",
        "outputId": "cae5faf3-569c-4784-eac9-47b600cee944"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 1.4168 - accuracy: 0.7192\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6916 - accuracy: 0.8495\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5203 - accuracy: 0.8722\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4474 - accuracy: 0.8838\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4064 - accuracy: 0.8906\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_17 (Flatten)        (32, 784)                 0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (32, 128)                 100480    \n",
            "                                                                 \n",
            " dense_35 (Dense)            (32, 10)                  1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Layer name: flatten_17\n",
            "Layer name: dense_34;\tActivation: sigmoid\n",
            "Layer name: dense_35;\tActivation: softmax\n",
            "Optimizer: <keras.optimizer_v2.gradient_descent.SGD object at 0x7f9ee03abd10>\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3749 - accuracy: 0.8984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(hidden_layers_activation='relu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUYcM1D6HhiI",
        "outputId": "7ce8c184-5ba7-4d0a-fc1c-524a329b7509"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6488 - accuracy: 0.8354\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3407 - accuracy: 0.9053\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2932 - accuracy: 0.9180\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2627 - accuracy: 0.9263\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2393 - accuracy: 0.9330\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_18 (Flatten)        (32, 784)                 0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (32, 128)                 100480    \n",
            "                                                                 \n",
            " dense_37 (Dense)            (32, 10)                  1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Layer name: flatten_18\n",
            "Layer name: dense_36;\tActivation: relu\n",
            "Layer name: dense_37;\tActivation: softmax\n",
            "Optimizer: <keras.optimizer_v2.gradient_descent.SGD object at 0x7f9ee02a2910>\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2241 - accuracy: 0.9382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(optimizer=keras.optimizers.Adam())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsqvgVJMIIdd",
        "outputId": "735e7d82-ec33-49c8-a65a-eca567c2ffc6"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3994 - accuracy: 0.8981\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1960 - accuracy: 0.9437\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1440 - accuracy: 0.9587\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1117 - accuracy: 0.9679\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0901 - accuracy: 0.9741\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_19 (Flatten)        (32, 784)                 0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (32, 128)                 100480    \n",
            "                                                                 \n",
            " dense_39 (Dense)            (32, 10)                  1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Layer name: flatten_19\n",
            "Layer name: dense_38;\tActivation: sigmoid\n",
            "Layer name: dense_39;\tActivation: softmax\n",
            "Optimizer: <keras.optimizer_v2.adam.Adam object at 0x7f9ee0203850>\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0993 - accuracy: 0.9704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(hidden_layers_activation='relu', optimizer=keras.optimizers.Adam())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e05TW6hJIT63",
        "outputId": "b76e5b61-ae0e-40f1-b625-7ca43f5ae125"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2614 - accuracy: 0.9251\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1136 - accuracy: 0.9668\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0776 - accuracy: 0.9770\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0589 - accuracy: 0.9819\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0454 - accuracy: 0.9861\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_20 (Flatten)        (32, 784)                 0         \n",
            "                                                                 \n",
            " dense_40 (Dense)            (32, 128)                 100480    \n",
            "                                                                 \n",
            " dense_41 (Dense)            (32, 10)                  1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Layer name: flatten_20\n",
            "Layer name: dense_40;\tActivation: relu\n",
            "Layer name: dense_41;\tActivation: softmax\n",
            "Optimizer: <keras.optimizer_v2.adam.Adam object at 0x7f9ee005bd10>\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0743 - accuracy: 0.9786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(\n",
        "    hidden_layers_activation='relu', \n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    hidden_layers_units=[512]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRmtiGHUJ95k",
        "outputId": "3b2a23f8-c8e6-4297-a44a-5840d7961fdc"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.2006 - accuracy: 0.9407\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0810 - accuracy: 0.9753\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0520 - accuracy: 0.9830\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0367 - accuracy: 0.9883\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0275 - accuracy: 0.9911\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_21 (Flatten)        (32, 784)                 0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (32, 512)                 401920    \n",
            "                                                                 \n",
            " dense_43 (Dense)            (32, 10)                  5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Layer name: flatten_21\n",
            "Layer name: dense_42;\tActivation: relu\n",
            "Layer name: dense_43;\tActivation: softmax\n",
            "Optimizer: <keras.optimizer_v2.adam.Adam object at 0x7f9edff1ec10>\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0729 - accuracy: 0.9792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(\n",
        "    hidden_layers_activation='relu', \n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    hidden_layers_units=[1024]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sFegYvBKjpS",
        "outputId": "75287f24-9d20-4c0d-d8af-dd34ac3ef151"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 15s 7ms/step - loss: 0.1844 - accuracy: 0.9442\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0750 - accuracy: 0.9769\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0490 - accuracy: 0.9843\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0347 - accuracy: 0.9885\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0258 - accuracy: 0.9916\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_22 (Flatten)        (32, 784)                 0         \n",
            "                                                                 \n",
            " dense_44 (Dense)            (32, 1024)                803840    \n",
            "                                                                 \n",
            " dense_45 (Dense)            (32, 10)                  10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 814,090\n",
            "Trainable params: 814,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Layer name: flatten_22\n",
            "Layer name: dense_44;\tActivation: relu\n",
            "Layer name: dense_45;\tActivation: softmax\n",
            "Optimizer: <keras.optimizer_v2.adam.Adam object at 0x7f9edfde9690>\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0786 - accuracy: 0.9790\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(\n",
        "    hidden_layers_activation='relu', \n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    hidden_layers_units=[128],\n",
        "    epochs=15\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uweh_tzDLKui",
        "outputId": "637f5bfe-62b9-42f5-96ce-8481d21c1495"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2571 - accuracy: 0.9272\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1141 - accuracy: 0.9660\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0789 - accuracy: 0.9758\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0585 - accuracy: 0.9819\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0436 - accuracy: 0.9870\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0356 - accuracy: 0.9886\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0277 - accuracy: 0.9913\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0224 - accuracy: 0.9930\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0181 - accuracy: 0.9946\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0160 - accuracy: 0.9949\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0111 - accuracy: 0.9967\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0125 - accuracy: 0.9959\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0098 - accuracy: 0.9967\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0085 - accuracy: 0.9973\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0075 - accuracy: 0.9975\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_23 (Flatten)        (32, 784)                 0         \n",
            "                                                                 \n",
            " dense_46 (Dense)            (32, 128)                 100480    \n",
            "                                                                 \n",
            " dense_47 (Dense)            (32, 10)                  1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Layer name: flatten_23\n",
            "Layer name: dense_46;\tActivation: relu\n",
            "Layer name: dense_47;\tActivation: softmax\n",
            "Optimizer: <keras.optimizer_v2.adam.Adam object at 0x7f9edffa1890>\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0847 - accuracy: 0.9791\n"
          ]
        }
      ]
    }
  ]
}